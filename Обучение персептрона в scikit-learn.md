parent: [[Обзор классификаторов на основе ML с использованием scikit-learn]]

tags: #ml #mlbookclub #reading #scikitlearn 

Демонстрацию будем проводить на том же датасете Iris. Присвоим длины и ширины лепестков в 150 образцах цветков матрице признаков `X`, а метки классов, соответствующие видам цветков - вектору `у`:

```python
from sklearn import datasets
import numpy as np

iris = datasets.load_iris()
X = iris.data[:, [2, 3]]
y = iris.target

print('Class labels:', np.unique(y))
```

```output
Class labels: [0 1 2]
```

Метки классов (имена классов цветков) уже сохранены в датасете в виде чисел. Это общепринятая практика для ML, позволяющая улучшить вычислительную эффективность, благодаря меньшему объему занимаемой памяти. Но scikit-learn может работать и с текстовыми метками, а не только с числами.

Чтобы разбить датасет на обучающую (train) и тестовые выборки (test) в sklearn существует функция `train_test_split`, с помощью которой можно автоматически разбить датасет с требуемыми характеристиками (размер подвыборок, перемешивание датасета и т.п.)

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=1, stratify=y)
```

`test_size` - это размер тестовой выборки, в данному случае - 30%, соответственно, в обучающую попадет 70%. С помощью `random_state` передается seed для перемешивания датасета. Его нужно указывать, чтобы можно было воспроизвести результаты в следующих экспериментах. `stratify=y` позволяет разбить датасет на подвыборки с таким же соотношением меток образцов, как во входящем датасете.

Как было сказано ранее, имеет смысл стандартизировать признаки, чтобы повысить эффективность алгоритма машинного обучения. Для этого в sklearn есть специальные инструменты, а для этого примера используем класс `StandardScaler`:

```python
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
sc.fit(X_train)
X_train_std = sc.transform(X_train)
X_test_std = sc.transform(X_test)
```

С помощью метода `fit` происходит оценка параметра $μ$ (выборочное среднее) и $\sigma$ (стандартное отклонение) для каждой размерности признаков из обучающих данных. А затем с помощью метода `transform` происходит стандартизация датасета. Причем, нужно обратить внимание, что вычисленные параметры применяются и к тестовому и к обучающему набору.

Далее нужно создать экземпляр класса `Perceptron`, задав также гиперпараметры - скорость обучения и количество эпох, и обучить модель методом `fit`:

```python
from sklearn.linear_model import Perceptron

ppn = Perceptron(eta0=0.1, random_state=1)
ppn.fit(X_train_std, y_train)
```

Большинство алгоритмов sklearn поддерживают многоклассовую классификацию, посредтсвом метода [[Методика OvA для многоклассовой классификации|OvA]], позволяющего подставлять в персептрон больше 2-х классов.

После того, как модель обучилась, можно делать на ее основе предсказания для новых образцов:

```python
y_pred = ppn.predict(X_test_std)
print('Misclassified examples: %d' % (y_test != y_pred).sum())
```

```output
Misclassified examples: 1
```

А также оценить метрики:

```python
from sklearn.metrics import accuracy_score

print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))
```

```output
Accuracy: 0.978
```

В sklearn есть довольно много уже готовых метрик для оценки качества моделей.

Если построить границы разделения классов, то можно увидеть, что линейных границ не достаточно для того, чтобы полностью разделить классы:

![[Screenshot 2023-11-27 at 18.49.30.png]]

А так как алгоритм персептрона никогда не сходится, если классы невозможно разделить линейно, то на практике его применяют редко.

У класса `Perseptron` есть много дополнительных параметров, которые можно посмотреть в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html).

