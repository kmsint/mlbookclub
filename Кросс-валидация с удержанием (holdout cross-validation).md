parent: [[Освоение практического опыта оценки моделей и настройки гиперпараметров]]

tags: #ml #cross-validation #mlbookclub 

Классическим подходом для оценки обобщающей способности ML-моделей является кросс-валидация с удержанием. Суть ее сводится к разбиению датасета на трейн и тест и обучение разных моделей на одном и том же трейне, а оценка на одном и том же тесте. Но при этом если все время использовать один и тот же тестовый набор для оценки модели, то он как бы становится частью трейна и есть вероятность, что на новых данных, которые модель еще не видела, модель будет себя показывать значительно хуже, чем на тесте.

Для решения этой проблемы используют усовершенствование алгоритма кросс-валидации с удержанием - разбивают датасет на три части - трейн, тест и валидационный (проверочный). Обучение моделей происходит на трейне, а отбор лучшей модели на вадидационном наборе. Таким образом модели никогда не видят тестовые данные и, соотвественно, не могут под них подстроиться. И только в самом конце происходит оценка эффективности лучшей модели на тестовых данных.

![[Pasted image 20231223153353.png]]

Недостаток метода перекрестной проверки с удержанием в том, что оценка эффективности может быть очень чувствительной к способу разбиения обучающего набора на обучающий и проверочный поднаборы; для разных образцов данных оценка будет варьироваться.

Чтобы побороть данных недостаток используют [[Кросс-валидация по k-блокам (k-fold cross-validation)|кросс-валидацию с разбиением на k-блоков]].

