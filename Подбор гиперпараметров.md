parent: [[Обучение простых ML-алгоритмов для классификации]]

tags: #reading #mlbookclub #ml 

На практике алгоритмы машинного обучения требуют некоторой доли экспериментирования, чтобы найти хорошую скорость обучения для оптимального схождения. 

Для персептрона и Adaline такими гиперпараметрами, требующими настройки вручную (в отличие от параметров модели (весов), которые подбираются автоматически), являются количество эпох обучения и скорость обучения.

При неправильной настройке гиперпараметров могут возникать определенные проблемы. Например, если если взять слишком маленькую скорость обучения, то понадобится большое количество эпох, чтобы алгоритм сошелся. А если выбрана слишком большая скорость обучения, то алгоритм может проскочить глобальный минимум функции потерь и сходимость не будет достигнута никогда. В таком случае говорят о расходимости алгоритма.

![[Screenshot 2023-11-23 at 20.20.45.png]]

