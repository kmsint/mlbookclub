parent: [[Обзор классификаторов на основе ML с использованием scikit-learn]]

tags: #ml #mlbookclub #reading #scikitlearn #logistic_regression 

Существует много различных алгоритмов оптимизации. Чтобы свести к минимуму выпуклую функцию потерь, такую как потери логистическои регрессии, рекомендуется использовать более развитые методики, нежели обыкновенный стохастический градиентный спуск (SGD). В scikit-learn реализован целый ряд алгоритмов оптимизации, которые можно указывать через параметр `solver`. Например, 'newton-cg ', 'lЬfgs ', 'liЫinear ', 'sag', 'saga'.

