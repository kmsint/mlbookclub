parent: [[Обучение простых ML-алгоритмов для классификации]]

tags: #reading #mlbookclub #ml 

Вся идея нейрона Маккалока и Питтса, а также персептрона Розенблата заключается в том, отдельный нейрон, в зависимости от входа либо активируется, либо нет.

Алгоритм персептрона может быть сведен к следующим шагам:

1. Инициализировать веса и смещение нулями или небольшими случайными значениями
2. Для каждого обучающего образца $x^{(i)}$:
	1. Вычислить выходное значение $\hat{y}$ 
	2. Обновить веса и смещение

Здесь выходным значением является метка прогнозируемого класса, а одновременное обновление весов формально может быть записано так:
$$\begin{align}&w_j:=w_j+\Delta w_j\\&b_j:=b_j+\Delta b_j\end{align}$$
Обновляющее значение для $\Delta w_j$ вычисляется следующим образом:

$$\begin{align*}&\Delta w_j=\eta(y^{(i)}-\hat{y}^{(i)})x_j^{(i)}\\&и \\&\Delta b=\eta(y^{(i)}-\hat{y}^{(i)})\end{align*}$$
где $\eta$ - скорость обучения (learning rate) - обычно константа между 0 и 1. $y^{(i)}$ - истинная метка класса i-го образца, а $\hat{y}^{(i)}$ - спрогнозированная метка класса. Важно отметить, что все веса в векторе весов обновляются одновременно, т.е. мы не вычисляем повторно спрогнозированную метку $\hat{y}^{(i)}$ до того, как все обновятся через соответствующие обновляющие значения $\Delta w_j$ 

Например, для двумерного набора данных можно было бы записать обновление так:

$$\begin{align*}&\Delta w_1=\eta(y^{(i)}-output^{(i)})x_1^{(i)}\\&\Delta w_2=\eta(y^{(i)}-output^{(i)})x_2^{(i)}\\&\Delta b=\eta(y^{(i)}-output^{(i)})\end{align*}$$

Важно отметить, что сходимость персептрона гарантируется лишь тогда, когда два класса линейно разделимы и скорость обучения достаточно мала. Если два класса не могут быть разделены линейной границей решения, то можно установить максимальное количество проходов (эпох) через датасет и/или пороговое число допустимых неправильных классификаций - в противном случае персептрон никогда не прекратит обновление весов.

![[Screenshot 2023-11-21 at 23.43.26.png]]

Общая концепция персептрона продемонстрирована на диаграмме

![[Screenshot 2023-11-21 at 23.44.54.png]]
