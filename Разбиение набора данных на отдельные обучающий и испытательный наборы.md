parent: [[Построение хороших обучающих наборов - предварительная обработка данных]]

tags: #ml #mlbookclub #reading 

Сравнение прогнозов с истинными метками классов можно понимать как несмещенную (неискаженную) оценку эффективности модели перед ее запуском в продакшн.

Удобный способ случайного разбиения набора данных на отдельные тестовый и обучающий поднаборы предусматривает применение функции `train_test_split` из подмодуля `model_selection` библиотеки scikit-learn. Продемонстрировать это можно на готовом наборе данных [[Dataset Wine|Wine]]

```python
df_wine = pd.read_csv('https://archive.ics.uci.edu/'
                      'ml/machine-learning-databases/wine/wine.data',
                      header=None)

df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',
                   'Alcalinity of ash', 'Magnesium', 'Total phenols',
                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
                   'Proline']

print('Class labels', np.unique(df_wine['Class label']))
df_wine.head()
```

![[Screenshot 2023-12-10 at 15.17.16.png]]

```python
from sklearn.model_selection import train_test_split

X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values

X_train, X_test, y_train, y_test =\
    train_test_split(X, y, 
                     test_size=0.3, 
                     random_state=0, 
                     stratify=y)
```

Установкой `test_size=0.3` мы присваиваем 30% образцов вин `Х_test` и `у_test`, а оставшиеся 70% образцов вин - `Х_train` и `у_train`. Предоставление массива меток классов `у` как аргумента для `stratify` гарантирует, что и обучающий, и испытательный набор данных имеют такие же доли классов, как у исходного набора данных.

[[Выбор подходящей пропорции для разделения набора данных на трейн и тест]]

