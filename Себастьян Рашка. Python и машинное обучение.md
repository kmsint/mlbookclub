parent: [[Список прочитанных книг и ссылок на конспекты]]

tags: #read_books #book #book_club 

### Ссылки

[Репозиторий 3-го издания](https://github.com/rasbt/python-machine-learning-book-3rd-edition) (2020 г)
[Репозиторий 4-го издания](https://github.com/rasbt/machine-learning-book) (2023 г)
### Содержание конспекта

1. [[Вопросы по ходу чтения книги Python и машинное обучение]]
2. [[Почему Python]]
3. [[Для кого эта книга]]
4. [[Что в этой книге]]
5. [[Наделение компьютеров способностью обучения на данных]]
	1. [[Общие понятия ML]]
	2. [[Три типа обучения и основная терминология]]
	3. [[Строительные блоки для успешного проектирования систем ML]]
	4. [[Установка и настройка Python для анализа данных и ML]]
6. [[Обучение простых ML-алгоритмов для классификации]]
	1. [[Первые идеи относительно нейронных сетей]]
	2. [[Формальное определение искусственного нейрона]]
	3. [[Правило обучения персептрона]]
	4. [[Реализация алгоритма обучения персептрона на Python]]
	5. [[Методика OvA для многоклассовой классификации]]
	6. [[Сходимость персептронов]]
	7. [[Адаптивные линейные нейроны и сходимость обучения (Adaline)]]
	8. [[Минимизация функции потерь с помощью градиентного спуска]]
	9. [[Реализация алгоритма обучения Adaline на Python]]
	10. [[Подбор гиперпараметров]]
	11. [[Улучшение градиентного спуска посредством масштабирования признаков]]
	12. [[Стохастический градиентный спуск]]
	13. [[Мини-пакетный градиентный спуск]]
7. [[Обзор классификаторов на основе ML с использованием scikit-learn]]
	1. [[Выбор алгоритма классификации]]
	2. [[5 главных шагов,  выполняемых при обучении ML-алгоритма]]
	3. [[Обучение персептрона в scikit-learn]]
	4. [[Моделирование вероятностей классов с помощью логистической регрессии]]
	5. [[Обучение весов модели через логистическую функцию потерь]]
	6. [[Обучение логистической регрессионной модели с помощью scikit-learn]]
	7. [[Решение проблем с переобучением с помощью регуляризации]]
	8. [[Классификация с максимальным зазором с помощью метода опорных векторов]]
	9. [[Понятие максимального зазора]]
8. [[Построение хороших обучающих наборов - предварительная обработка данных]]
	1. [[Решение проблемы с недостающими данными]]
		1. [[Идентификация недостающих значений в табличных данных]]
		2. [[Удаление строк или признаков, в которых есть недостающие значения]]
		3. [[Условный расчет недостающих значений]]
	2. [[API-интерфейс оценщиков sklearn]]
	3. [[Обработка категориальных данных]]
		1. [[Кодирование категориальных данных с помощью pandas]]
			1. [[Маппинг порядковых признаков]]
			2. [[Кодирование меток классов]]
			3. [[One-hot encoding на именных признаках]]
			4. [[Кодирование порядковых признаков]]
	4. [[Разбиение набора данных на отдельные обучающий и испытательный наборы]]
		1. [[Выбор подходящей пропорции для разделения набора данных на трейн и тест]]
	5. [[Приведение признаков к одному масштабу]]
		1. [[Нормализаци признаков (normalization)]]
		2. [[Стандартизация признаков (standartization)]]
	6. [[Выбор значимых признаков]]
		1. [[Регуляризация L1 и L2 как штрафы за сложность модели]]
		2. [[Геометрическая интерпретация регуляризации L2]]
		3. [[Разреженные решения с регуляризацией L1]]
		4. [[Алгоритмы последовательного выбора признаков]]
9. [[Сжатие данных с помощью понижения размерности]]
	1. [[Анализ главных компонентов (PCA - Principal Component Analysis)]]
		1. [[Основные шаги при анализе главных компонентов]]
	2. [[Линейный дискриминантный анализ (LDA - Linear Diskriminant Analysis)]]
		1. [[Основные шаги при линейном дискриминантном анализе]] 