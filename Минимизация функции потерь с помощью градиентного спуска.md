parent: [[Обучение простых ML-алгоритмов для классификации]]

tags: #reading #mlbookclub #ml 

Одной из ключевых частей любого ML-алгоритма в рамках обучения с учителем является определенная целевая функция, которая должна быть оптимизирована в процессе обучения. Для Adaline можно определить функцию потерь как среднеквадратичную ошибку (mean of squared errors - MSE) между вычисленным результатом и истинной меткой класса.

	В третьем издании книги написано про SSE - сумму квадратичных ошибок формула почти такая же, но без n в знаменателе

$$L(w, b)=\frac{1}{2n}\sum_{i=1}^n(y^{(i)}-\sigma(z^{(i)}))^2$$

Коэффициент $\frac{1}{2}$ введен в формулу для удобства дальнейшего выведения градиента функции потерь.

Основное преимущество непрерывной линейной функции активации по сравнению со ступенчатой функцией заключается в том, что непрерывную функцию можно дифференцировать. 

Еще одна приятная черта такой функции потерь состоит в том, что она выпуклая и к ней можно применить простой и мощный алгоритм оптимизации - градиентный спуск для подбора весов модели.

На рисунке ниже видно, что главная идея градиентного спуска состоит в том, что можно спускаться вниз, пока не будет достигнут локальный или глобальный минимум функции потерь.

![[Screenshot 2023-11-23 at 14.11.18.png]]

На каждой итерации мы делаем шаг в направлении, противоположном градиенту, где размер шага определяется величиной скорости обучения, а также наклоном градиента.

С использованием градиентного спуска мы можем обновлять веса путем совершения шага в направлении, противоположном градиенту $\nabla L(w, b)$ функции потерь $L(w, b)$:
$$w:=w+\Delta w,\quad b:=b+\Delta b$$
Изменение весов и смещения определяется как отрицательный градиент, умноженный на скорость обучения $\eta$:
$$\Delta w=-\eta \nabla_wL(w,b),\qquad \Delta b=-\eta \nabla_bL(w,b)$$

Чтобы вычислить градиент функции потерь, нужно посчитать частичную производную функции потерь по каждому весовому коэффициенту $w_j$:
$$\frac{\partial L}{\partial w_j}=-\frac{2}{n}\sum_i(y^{(i)}-\sigma(z^{(i)}))x_j^{(i)}$$
Точно также можно записать обновление для смещения:
$$\frac{\partial L}{\partial b}=-\frac{2}{n}\sum_i(y^{(i)}-\sigma(z^{(i)}))$$
Обратите внимание, что 2 в числителе выше — это просто постоянный коэффициент масштабирования, и мы могли бы опустить его, не влияя на алгоритм. Удаление коэффициента масштабирования имеет тот же эффект, что и изменение скорости обучения в 2 раза. Он приходит из квадрата функции потерь, когда по ней вычисляется производная.

![[Screenshot 2023-11-23 at 14.55.37.png]]

Таким образом, мы можем записать обновление веса как:
$$\Delta w_j=-\eta \frac{\partial L}{\partial w_j}\quad и \quad \Delta b=-\eta \frac{\partial L}{\partial b}$$
Так как все веса обновляются одновременно, правило обучения Adaline приобретает вид:
$$w:=w+\Delta w,\quad b:=b+\Delta b$$
Не смотря на то, что правило обучения Adaline выглядит похожим на правило обучения персептрона, нужно отметить, что $\sigma(z^{(i)})$, где $z^{(i)}=w^Tx^{(i)}+b$ - вещественное число, а не целочисленная метка класса.

Кроме того, обновление весов вычисляется на основе всех образцов в обучающем наборе (вместо пошаго­вого обновления весов после каждого образца), отчего данный подход также называют пакетным градиентным спуском (batch gradient descent).

Здесь [[Объяснение градиентного спуска|объяснение]] всего этого немного попроще.