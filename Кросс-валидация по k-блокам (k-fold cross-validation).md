parent: [[Освоение практического опыта оценки моделей и настройки гиперпараметров]]

tags: #ml #cross-validation #mlbookclub 

При перекрестной проверке по k блокам мы случайным образом разбиваем обучающий набор данных на $k$ блоков без возвращения, где $k - 1$ блоков используются для обучения моделей и один блок применяется для оценки эффективности. Указанная процедура повторяется $k$ раз, так что мы получаем $k$ моделей и оценок эффективности.

Затем нужно определить среднюю эффективность моделей на основе разных независимых испытательных блоков, чтобы получить оценку эффективности, которая менее чувствительна к добавочным разбиениям обучающих данных в сравнении с методом перекрестной проверки с удержанием. Обычно мы используем перекрестную проверку по k-блокам для настройки моделей, т.е. нахождения оптимальных значений гиперпараметров, которые обеспечат удовлетворительную эффективность обобщения, полученную из оценки эффективности моделей на испытательных блоках.

После того, как приемлемые значения гиперпараметров найдены, можно повторно обучить модель на полном обучающем наборе и получить финальную оценку эффективности с применением независимого испытательного набора. Логическое обоснование подгонки модели к полному обучающему набору после перекрестной проверки по k блокам заключается в том, что предоставление алгоритму обучения большего количества обучающих образцов обычно дает в результате более точную и надежную модель.

Поскольку перекрестная проверка по k-блокам является приемом повторной выборки без возвращения, ее преимущество в том, что каждая выборочная точка будет использоваться для обучения и проверки (как часть испытательного блока) в точности один раз, давая в итоге оценку с меньшей дисперсией, чем метод перекрестной проверки с удержанием.

![[Pasted image 20231223155348.png]]

Как показывают эмпирические данные, хорошим стандартным значением для $k$ в перекрестной проверке по k-блокам является 10. Например, эксперименты, проведенные Роном Кохави на разнообразных реальных наборах данных, наводят на мысль, что перекрестная проверка по 10 блокам обеспечивает наилучший компромисс между смещением и дисперсией.

Если же датасеты относительно небольшие, то имеет смысл брать $k$ болше 10, чтобы в обучающие наборы попадало больше данных. При этом чем больше $k$, тем дольше будет работать алгоритм кросс-валидации, поэтому всегда нужно находить компромисс.

Специальным случаем перекрестной проверки по k-блокам является метод перекрестной проверки по одному (leave-one-out cross-validation - LOOCV). Этот подход рекомендуется для маленьких датасетов.

Незначительным усовершенствованием подхода перекрестной проверки по k-блокам считается стратифицированная перекрестная проверка по k-блокам, которая может давать оценки с лучшим смещением и дисперсией, особенно в случаях неравных долей классов.

При стратифицированной перекрестной проверке доли классов предохраняются в каждом блоке, гарантируя тем самым, что каждый блок отображает доли классов в обучающем наборе данных. В sklearn для этого есть готовый класс - `StratifiedKFold`

