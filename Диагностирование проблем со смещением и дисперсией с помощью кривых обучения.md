parent: [[Освоение практического опыта оценки моделей и настройки гиперпараметров]]

tags: #ml #mlbookclub 

Если модель слишком сложная, то она плохо обобщается на не встречавшиеся ранее данные. Сократить степень переобучения может помочь добавление большего количества обучающих образцов. Но на практике такое может оказаться либо дорого, либо трудно осуществимо.

Построив графики показателей правильности обучения и проверки как функций размера обучающего набора, можно понять страдает ли модель от высокой дисперсии или высокого смещения, а также выяснить поможет ли сбор добавочных данных решить имеющуюся проблему.

Борьба с недообученностью модели (с высоким смещением):

- Увеличение параметров модели путем сбора или конструирования дополнительных признаков
- Уменьшение степени регуляризации

![[Pasted image 20231229003106.png]]

Справа сверху показана модель, которая страдает от высокой дисперсии, на что указывает крупный разрыв между показателями правильности обучения и перекрестной проверки. Чтобы решить проблему переобучения, мы можем собрать больше обучающих данных, снизить сложность модели либо увеличить значение параметра регуляризации.

В случае нерегуляризированных моделей снижению степени переобучения может также помочь уменьшение количества признаков посредством [[Выбор признаков (feature selection)|выбора признаков]] или [[Извлечение признаков (feature extraction)|выделения признаков]]. Наряду с тем, что сбор добавочных обучающих данных обычно имеет тенденцию снизить шансы переобучения, он не всегда может помочь, скажем, если обучающие данные крайне зашумлены или модель уже очень близка к оптимальной.

