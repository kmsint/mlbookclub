parent: [[Обучение весов модели через логистическую функцию потерь]]

tags: #ml #mlbookclub #reading #scikitlearn #logistic_regression 

Понятия вероятности и правдоподобия тесно связаны. Сравните два предложения:

- «Какова вероятность выпадения 12 очков в каждом из ста бросков двух костей?»
- «Насколько правдоподобно, что кости не шулерские, если из ста бросков в каждом выпало 12 очков?»

Если вероятность позволяет нам предсказывать неизвестные результаты, основанные на известных параметрах, то правдоподобие позволяет нам оценивать неизвестные параметры, основанные на известных результатах.

Правдоподобие является оценкой того, насколько выбранный закон распределения хорошо описывает конкретную подвыборку случайной величины, но сама по себе эта оценка имеет довольно мало смысла, а нужна для того, чтобы сравнить разные законы распределения между собой. 

Функция правдоподобия - это способ измерить, насколько хорошо определенные параметры модели соответствуют имеющимся данным. Она показывает некоторую оценку вероятности получить имеющиеся данные при конкретных значениях параметров модели.
### Правдоподобие математически

Пусть есть случайная величина $X$ и есть какой-то закон ее распределения. Его можно выразить через функцию вероятности или через функцию плотности вероятности $f(X,\theta)$, где $\theta$ - это параметр распределения. И $X$, и $\theta$ могут быть векторами.

Имеется выборка из $n$ значений случайной величины $X$: $x_1, x_2, \dots, x_n$ 

Функция правдоподобия $L$ зависит от параметра $\theta$:
$$L(\theta)=f(x_1,\theta) \cdot f(x_2,\theta)\cdot ... \cdot f(x_n,\theta)=\prod_{i=1}^nf(x_i,\theta)$$
Часто используется натуральный логарифм правдоподобия, который является суммой логарифмов:
$$lnL(\theta)=\sum_{i=1}^nlnf(x_i,\theta)$$
Зачем логарифм?

1. Произведение превращается в сумму: $\prod \rightarrow \sum$, а значит, проще дифференцировать (производная суммы равна сумме производных)
2. $\max ln(f)=\max f$ 

**Пример.** Пусть дан некоторый закон распределения, допустим, распределение Пуассона:
$$P(x,\theta)=\frac{\theta^xe^{-\theta}}{x!}$$
Также есть выборка $\vec{x}=(1, 4, 1, 1, 0, 5)$ 

Тогда правдоподобие можно вычислить так:
$$\begin{align}L(\theta)&=\prod_{i=1}^6P(x_i,\theta)=\frac{\theta^1e^{-\theta}}{1!}\cdot\frac{\theta^4e^{-\theta}}{4!}\cdot\frac{\theta^1e^{-\theta}}{1!}\cdot\frac{\theta^1e^{-\theta}}{1!}\cdot\frac{\theta^0e^{-\theta}}{0!}\cdot\frac{\theta^5e^{-\theta}}{5!}=\\&=\left(\frac{\theta^1e^{-\theta}}{1!}\right)^3\cdot\frac{\theta^4e^{-\theta}}{4!}\cdot\frac{\theta^0e^{-\theta}}{0!}\cdot\frac{\theta^5e^{-\theta}}{5!}=\frac{\theta^{12}e^{-6\theta}}{4!\cdot5!}\end{align}$$
И тогда натуральный логарифм от правдоподобия:
$$lnL(\theta)=ln\frac{\theta^{12}e^{-6\theta}}{4!\cdot5!}=ln\theta^{12}+ln(e^{-6\theta})-ln(4!\cdot5!)=12ln\theta-6\theta-ln(4!\cdot5!)$$

Получившееся выражение легко продифференцировать и найти его [[Оценка максимального правдоподобия|максимум]]
