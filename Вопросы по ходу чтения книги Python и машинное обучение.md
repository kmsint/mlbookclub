parent: [[Себастьян Рашка. Python и машинное обучение]]

tags: #ml #mlbookclub #book #questions

В процессе работы клуба решили с участниками создать отдельный раздел, где будем собирать ответы на вопросы, возникающие в процессе чтения.

1. **Как алгоритм машинного обучения подгоняет помеченные обучающие данные к прогнозирующей модели?**

Существуют разные способы, среди которых базовым и основным считается алгоритм обратного распространения ошибки в разных модификациях. Суть его в том, что вычисляется разница между истинным значением метки образца и предсказанным значением и, в зависимости, от того, на сколько модель ошиблась - корректируются ее веса.

2. **Что такое дискретные классы?**

Дискретные - значит, что этих классов конечное число. Противоположность дискретным величинам представляют величины непрерывные, когда число их возможных значений бесконечно. Отсюда 2 основные задачи машинного обучения - классификация, когда требуется отнести объект к какому-то классу из конечного списка классов и регрессия, когда нужно предсказать число из бесконечного количества возможных чисел.

3. **Для регрессии что означает результирующий сигнал представляет собой непрерывную величину?**

Выше, кажется, уже ответил на этот вопрос. Непрерывная, значит, на любом диапазоне бесконечное число конкретных значений.

4. **Чем является понижение размерности в аспекте обучения без учителя?**

Понижение размерности - это уменьшение размерности пространства признаков. То есть, если какой-то объект представлен в виде вектора в 100-мерном пространстве, то если мы уменьшим количество измерений до, например, 90, то это и будет понижением размерности.

5. **Что такое трёхмерный швейцарский рулет?**

Вот это он:

![[Pasted image 20231122123605.png]]

В контексте машинного обучения имеется в виду развернуть его из 3-хмерного измерения в двумерное вот так:

![[Pasted image 20231122123721.png]]

6. **Что означает слово "неупорядоченные" во фразе "задача классификации сводится к назначению образцам категориальных неупорядоченных меток"?**

Значит, что у классов, на которые указывают метки, нет никакого порядка. Можно любой из них считать хоть первым, хоть последним, хоть центральным. Кошечки не главнее собак, а собачки не главнее кошечек в задаче классификации кошечек и собачек.

7. **Что такое прогнозирование непрерывных результатов?**

Это как раз предсказание какого-то конкретного значения из бесконечного числа возможных.

8. **Что такое поясняющие переменные прогнозаторы?**

Это входные значения для модели регрессии (и не только регрессии). То есть, чтобы спрогнозировать какое-то значение нужно что-то получить на вход. Вот, этот вход и является таким прогнозатором. Терминология несколько корявая. Обычно их называют признаками или фичами.

9. **А что такое переменная непрерывного отклика?**

Это какая-то переменная, которая выдает непрерывное значение. Можно представить ее как значение амплитуды колебания какого-то сигнала. Например, колебание курса валют. Вот переменная, которая постоянно выдает значение курса какой-то валюты и есть такая переменная.

10. **Как можно найти между ними взаимосвязь?**

Выяснить какому закону они подчиняются. Допустим, у нас есть датасет с температурой по Цельсию и соответствующие этом датасету метки с температурой по Фаренгейту. Нам нужно как-то понять из этих наборов данных как связаны температуры в разных шкалах. В данном примере все просто, можно аналитически вывести формулу линейной зависимости, потому что зависимость здесь как раз очень простая. В более сложных случаях, когда такая зависимость неочевидна и аналитически получена быть или не может, или требует много ресурсов, задачу можно решить методами машинного обучения. Точность будет ниже, чем у аналитического решения, но во многих случаях сильно высокая она и не нужна. Но зато будет модель, которая сможет решать нашу задачу в каких-то допустимых границах.

11. **Что такое среднеквадратическое расстояние?**

Здесь, возможно, имеется в виду среднеквадратичное отклонение. Если не вдаваться в детали - это квадратный корень из дисперсии случайной величины.

12. **Что такое свободный член и наклон, выясненные из имеющихся данных?**

Формула прямой, разделяющей данные может быть описана в виде:
$$y=kx+b$$
Здесь $k$ - коэффициент, отвечающий за наклон, а $b$ - свободный член, отвечающий за смещение этой прямой. В формулах линейной регрессии, обычно вместо $k$ пишут $w_1$, а вместо $b$ пишут $w_0$, то есть так:
$$y=w_1x_1 + w_0$$
И тогда наклон - это $w_1$, а свободный член - это $w_0$. Для практики, возможно имеет смысл на бумаге построить графики прямых с разными весовыми коэффициентами $w_1$ и $w_0$, чтобы понять как именно они влияют на прямую.

13. Что такое логический вентиль?

Это базовый элемент логической схемы, выполняющий элементарную логическую операцию (И, НЕ, ИЛИ и т.п.)

14. Как соотносится масштабирование признаков и понижение размерности?

Масштабирование признаков используют для того, чтобы все значения перевести в одну шкалу. Т.е. если есть признаки, которые измеряются тысячами, а другие десятками, то первые будут вносить больший вклад в предсказания модели (если мы про перцептрон), поэтому их нормируют в диапазон от 0 до 1.

Понижение размерности - приём, который используют для уменьшения количества признаков в датасете.

15. Что такое параметрические модели и зачем нужна подгонка их параметров?

Параметрические модели это те модели, которые имеют параметры, т.е. в данном случае параметры перцептрона это его веса $w$. Есть непараметрические  модели, например, kNN. Подгонка параметров это процесс обучения, с помощью некоторого алгоритма мы подбираем значения этих коэффициентов так, чтобы они наилучшим образом приближали наши данные.

16. В чем главные отличия loss и cost функций?

Отличий нет, это синонимы

17. Почему двоичная классификация для классов 1 и -1, а не, например, 0 и 1, или каких-то других? Насколько это принципиально?

В 4-м издании как раз заменили на 0 и 1. Не сильно принципиально

18. Функция решения и зависимая величина - это одно и тоже?

Нет, зависимая величина - это таргет, то, что нужно предсказать, а функция решения - это та функция, по выходу которой мы понимаем, что предсказано

19. Функция решения и функция активации это одно и тоже?

В какой-то степени да. Но после активационной функции сигнал обычно идет на следующий вход, после которого опять может быть активационная функция, а на выходе решающей фукнции обычно уже предсказание модели. Но по сути одно и то же.

20. Общий вход $z$ - это сумма попарных произведений значений (или точек?) вектора весов и вектора входных значений?

Да

21. Транспонирование относится к скалярному произведению векторов?

Транспонирование матрицы - это такая операция над матрицей, когда строки становятся столбцами, а столбцы строками.
$$M=\left[\begin{matrix}1 && 1 && 1\\2 && 2 && 2\\3 && 3 && 3\end{matrix}\right]$$
$$M^T=\left[\begin{matrix}1 && 2 && 3\\1 && 2 && 3\\1 && 2 && 3\end{matrix}\right]$$
